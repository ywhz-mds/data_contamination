{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('dataset/valid.json', 'r',encoding='utf-8') as f:\n",
    "    valid_data = json.load(f)\n",
    "\n",
    "texts = [item['text'] for item in valid_data]\n",
    "labels = [0 if item['label'] == 'clean' else 1 for item in valid_data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "# import torch\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# 现在你的代码中的随机操作应该是可重复的，无论它们是否在 GPU 上运行\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"detected_model\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"detected_model\", torch_dtype=torch.bfloat16).to(device)\n",
    "\n",
    "def extract_features(texts, tokenizer, model):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for text in tqdm(texts):\n",
    "            inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            last_hidden_state = outputs.hidden_states[-1]  # last hidden state\n",
    "            feature = last_hidden_state.mean(dim=1)  # mean pooling\n",
    "            features.append(feature.float().cpu().numpy())\n",
    "    return torch.tensor(features)\n",
    "\n",
    "features = extract_features(texts, tokenizer, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(features.shape)\n",
    "# for feature in features:\n",
    "#     print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# print(features.shape)\n",
    "# print(labels.shape)\n",
    "# 构造 TensorDataset\n",
    "dataset = TensorDataset(features, torch.tensor(labels))\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# 假设你想要80%的数据作为训练集，20%的数据作为测试集\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "# 使用 random_split 来拆分数据集\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "batch_size = 16\n",
    "# 现在你可以创建 DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n",
    "# print(train_dataloader.dataset.tensors[0].shape)\n",
    "# print(test_dataloader.dataset.tensors[0].shape)\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 获取训练数据的一个批次\n",
    "# train_batch = next(iter(train_dataloader))\n",
    "# print(\"Train batch shape:\")\n",
    "# for item in train_batch:\n",
    "#     print(item.shape)\n",
    "\n",
    "# # 获取测试数据的一个批次\n",
    "# test_batch = next(iter(test_dataloader))\n",
    "# print(\"Test batch shape:\")\n",
    "# for item in test_batch:\n",
    "#     print(item.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# 加载 BERT 模型和 tokenizer\n",
    "tokenizer2 = BertTokenizer.from_pretrained('gaunernst/bert-medium-uncased')\n",
    "model2 = BertForSequenceClassification.from_pretrained('gaunernst/bert-medium-uncased', num_labels=2).to(device)\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = AdamW(model2.parameters(), lr=2e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 训练模型\n",
    "model2.train()\n",
    "epochs = 8\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    for batch in train_dataloader:\n",
    "        b_features, b_labels = batch\n",
    "        b_features = b_features.to(device)\n",
    "        b_labels = b_labels.to(device)\n",
    "\n",
    "        outputs = model2(inputs_embeds=b_features, labels=b_labels)\n",
    "        logits = outputs.logits\n",
    "        # probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        # print(probabilities.shape)\n",
    "        # print(probabilities[:, 1])\n",
    "        # print(b_labels.shape)\n",
    "        # 收集所有概率和标签\n",
    "        # threshold = 0.5\n",
    "        # binary_predictions = (probabilities[:, 1] >= probabilities[:,0]).float()\n",
    "        loss = criterion(logits, b_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 开始测试\n",
    "    model2.eval()  # 设置模型为评估模式\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            b_features, b_labels = batch\n",
    "            b_features = b_features.to(device)\n",
    "            b_labels = b_labels.to(device)\n",
    "\n",
    "            outputs = model2(inputs_embeds=b_features)\n",
    "            _, preds = torch.max(outputs.logits, 1)\n",
    "            all_preds.extend(preds.tolist())\n",
    "            all_labels.extend(b_labels.tolist())\n",
    "\n",
    "    print(classification_report(all_labels, all_preds))  # 打印分类报告\n",
    "    # 评估模型\n",
    "# model2.eval()\n",
    "\n",
    "    all_probabilities = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            b_features, b_labels = batch\n",
    "            b_features = b_features.to(device)\n",
    "            b_labels = b_labels.to(device)\n",
    "\n",
    "            logits = model2(inputs_embeds=b_features, labels=b_labels).logits\n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            # print(probabilities.shape)\n",
    "            # print(probabilities[:, 1])\n",
    "            # print(b_labels)\n",
    "            # 收集所有概率和标签\n",
    "            # threshold = 0.5\n",
    "            binary_predictions = (probabilities[:, 1] >= probabilities[:,0]).long()\n",
    "            # all_predictions.append()\n",
    "            all_probabilities.append(binary_predictions)\n",
    "            all_labels.append(b_labels )\n",
    "    # 检查标签分布\n",
    "    # print(\"Label distribution:\", {label: all_labels.count(label) for label in set(all_labels)})\n",
    "\n",
    "    # 将所有概率和标签拼接成单个张量\n",
    "    all_probabilities = torch.cat(all_probabilities)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    print(all_probabilities.shape)\n",
    "    print(all_labels.shape)\n",
    "    # 计算 AUC\n",
    "    try:\n",
    "        auc_score = roc_auc_score(all_probabilities.cpu(), all_labels.cpu())\n",
    "        print(f\"AUC: {auc_score.item()}\")\n",
    "    except:\n",
    "        continue\n",
    "    model2.train()  # 设置模型回到训练模式\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "from torchmetrics.classification import BinaryAUROC\n",
    "\n",
    "# 初始化 AUC 计算器\n",
    "auc = BinaryAUROC()\n",
    "\n",
    "# 评估模型\n",
    "model2.eval()\n",
    "\n",
    "all_probabilities = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        b_features, b_labels = batch\n",
    "        b_features = b_features.to(device)\n",
    "        b_labels = b_labels.to(device)\n",
    "\n",
    "        logits = model2(inputs_embeds=b_features, labels=b_labels).logits\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        # print(probabilities.shape)\n",
    "        # print(probabilities[:, 1])\n",
    "        # print(b_labels.shape)\n",
    "        # 收集所有概率和标签\n",
    "        # threshold = 0.5\n",
    "        binary_predictions = (probabilities[:, 1] >= probabilities[:,0]).long()\n",
    "        # all_predictions.append()\n",
    "        all_probabilities.append(binary_predictions)\n",
    "        all_labels.append(b_labels )\n",
    "\n",
    "# 将所有概率和标签拼接成单个张量\n",
    "all_probabilities = torch.cat(all_probabilities)\n",
    "all_labels = torch.cat(all_labels)\n",
    "print(all_probabilities[-11])\n",
    "print(all_labels[-11])\n",
    "# 计算 AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc_score = roc_auc_score(all_probabilities.cpu(), all_labels.cpu())\n",
    "print(f\"AUC: {auc_score.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 all_probabilities 和 all_labels 是长度相同的列表或者张量\n",
    "probabilities = all_probabilities.cpu().numpy()\n",
    "labels = all_labels.cpu().numpy()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(labels, probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
