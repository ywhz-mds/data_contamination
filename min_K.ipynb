{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuxingyu/anaconda3/lib/python3.11/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "##加载模型\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import math\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"detected_model\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"detected_model\", torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from json...\n"
     ]
    }
   ],
   "source": [
    "#加载数据集\n",
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = \"True\"\n",
    "flatten = lambda l : [x for s in l for x in s]\n",
    "shuffle = lambda l : random.sample(l, k=len(l))\n",
    "data_path='dataset/valid.json'\n",
    "print(\"loading from json...\")\n",
    "with open(data_path, 'r') as f:\n",
    "    data = f.read()\n",
    "    lines=json.loads(data)\n",
    "sentences=[d['text'] for d in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用min-K prob 方法 伪代码如下：\n",
    "1: Input: A sequence of tokens x = x1, x2, ..., xN , decision threshold ϵ\n",
    "2: Output: Membership of the sequence x\n",
    "3: for i = 1 to N do\n",
    "4: Compute − log p(xi|x1, . . . , xi−1)\n",
    "5: end for\n",
    "6: Select the top k% of tokens from x with the lowest probability and add to Min-k%(x)\n",
    "7: MIN-K% PROB(x) = P xi∈Min-k%(x) − log p(xi|x1, ..., xi−1)\n",
    "8: If MIN-K% PROB(x) > ϵ : return Non-member Else: return Member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 705/705 [00:00<00:00, 56964.77it/s]\n",
      "100%|██████████| 729/729 [00:00<00:00, 65164.48it/s]\n",
      "100%|██████████| 767/767 [00:00<00:00, 60531.95it/s]\n",
      "100%|██████████| 947/947 [00:00<00:00, 66661.17it/s]\n",
      "100%|██████████| 852/852 [00:00<00:00, 55910.05it/s]\n",
      "100%|██████████| 747/747 [00:00<00:00, 61431.81it/s]\n",
      "100%|██████████| 1281/1281 [00:00<00:00, 49528.52it/s]\n",
      "100%|██████████| 827/827 [00:00<00:00, 68230.25it/s]\n",
      "100%|██████████| 1036/1036 [00:00<00:00, 56024.28it/s]\n",
      "100%|██████████| 704/704 [00:00<00:00, 53626.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success!\n"
     ]
    }
   ],
   "source": [
    "#min-k prob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "sum_min_k_prob=[]\n",
    "for j in range(len(sentences)):\n",
    "    sentence=sentences[-j]\n",
    "\n",
    "    input_id=tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "\n",
    "    outputs = model.forward(input_ids=input_id)\n",
    "\n",
    "    logit = outputs.logits\n",
    "\n",
    "    prob = F.softmax(logit, dim=-1)\n",
    "\n",
    "    sum_prob=[]\n",
    "    for i in tqdm(range(1,len(prob[0]))):\n",
    "        p=prob[0,i,input_id[0,i]]\n",
    "        sum_prob.append(p)\n",
    "\n",
    "    sorted_prob=sorted(sum_prob)\n",
    "    k=2 #超参数\n",
    "    min_k=len(sentence)*k//100\n",
    "\n",
    "    selected_prob=sorted_prob[:min_k]\n",
    "\n",
    "    log_probs=[]\n",
    "\n",
    "    for i in range(len(selected_prob)):\n",
    "        log_probs.append(-1*math.log(selected_prob[i]))\n",
    "\n",
    "    min_k_prob=np.mean(log_probs)\n",
    "\n",
    "    sum_min_k_prob.append(\n",
    "        {\n",
    "            'text':sentence,\n",
    "            'min_k_prob':min_k_prob\n",
    "        }\n",
    "    )\n",
    "\n",
    "with open('sum_min_k_prob_d.json', 'w') as f:\n",
    "    json.dump(sum_min_k_prob, f)\n",
    "\n",
    "print(\"success!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
