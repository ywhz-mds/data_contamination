{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##加载模型\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"detected_model\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"detected_model\", torch_dtype=torch.bfloat16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据集\n",
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = \"True\"\n",
    "flatten = lambda l : [x for s in l for x in s]\n",
    "shuffle = lambda l : random.sample(l, k=len(l))\n",
    "data_path='dataset/synonym_replacement_valid.json'\n",
    "print(\"loading from json...\")\n",
    "with open(data_path, 'r',encoding = 'utf-8') as f:\n",
    "    data = f.read()\n",
    "    lines=json.loads(data)\n",
    "tokens=[d['text'] for d in lines]\n",
    "print(lines[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算困惑度\n",
    "model.eval()\n",
    "token=tokens[0]\n",
    "token_len=len(token)\n",
    "input_ids=tokenizer.encode(token,return_tensors='pt')\n",
    "#print(input_ids)\n",
    "nlls=[]#存储每个片段的负对数似然值\n",
    "prev_end_loc=0#上一个片段的结束位置\n",
    "stride=30#这个地方应该可以调的\n",
    "max_length=40#这个地方也可以调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for begin_loc in tqdm(range(0,token_len,stride)):\n",
    "    end_loc=min(begin_loc+max_length,token_len)\n",
    "    if end_loc==token_len:\n",
    "        break\n",
    "    trg_len=end_loc-prev_end_loc\n",
    "    input=input_ids[:,begin_loc:end_loc].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs=model(input_ids,labels=input_ids)\n",
    "        log_likelihood=outputs.loss\n",
    "    nlls.append(log_likelihood)\n",
    "    prev_end_loc=end_loc\n",
    "ppl=torch.exp(torch.stack(nlls).mean())\n",
    "print(\"perplexity:\",ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_perplexity=[]\n",
    "for i in range(len(lines)):\n",
    "    # 输入句子\n",
    "    # sentence = tokens[i]\n",
    "    sentence = lines[i]['text']\n",
    "\n",
    "    # 将句子分词并转换为模型的输入格式\n",
    "    input_ids = tokenizer.encode(sentence, return_tensors='pt').to(device)\n",
    "\n",
    "    # 使用模型预测每个词的概率\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "\n",
    "    # 计算困惑度\n",
    "    perplexity = torch.exp(loss)\n",
    "    sum_perplexity.append({\n",
    "        'text': sentence,\n",
    "        'label': lines[i]['label'],\n",
    "        'perplexity': perplexity.item()\n",
    "    })\n",
    "    # sum_perplexity.append(perplexity.item())\n",
    "\n",
    "# with open('perplexity.json', 'w') as f:\n",
    "#     json.dump(sum_perplexity, f)\n",
    "with open('perplexity-synonym.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sum_perplexity, f, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import numpy as np\n",
    "# 指定字体\n",
    "font = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\", size=14)\n",
    "\n",
    "# 加载你的数据\n",
    "with open('perplexity-synonym.json','r',encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 将数据分为clean和dirty两部分\n",
    "data_clean = [d for d in data if d['label'] == 'clean']\n",
    "data_dirty = [d for d in data if d['label'] == 'dirty']\n",
    "\n",
    "# 提取perplexity值\n",
    "perplexity_clean = [d['perplexity'] for d in data_clean]\n",
    "perplexity_dirty = [d['perplexity'] for d in data_dirty]\n",
    "\n",
    "# # 创建横坐标值\n",
    "# items_clean = list(range(1, len(perplexity_clean) + 1))\n",
    "# items_dirty = list(range(1, len(perplexity_dirty) + 1))\n",
    "\n",
    "# # 绘制折线图\n",
    "# plt.plot(items_clean, perplexity_clean, label='clean')\n",
    "# plt.plot(items_dirty, perplexity_dirty, label='dirty')\n",
    "\n",
    "# plt.xlabel('Item数', fontproperties=font)\n",
    "# plt.ylabel('困惑度', fontproperties=font)\n",
    "# plt.title('Clean和Dirty的困惑度走势', fontproperties=font)\n",
    "# plt.legend(prop=font)\n",
    "\n",
    "# plt.show()\n",
    "# 创建横坐标值\n",
    "# items_clean = np.arange(1, len(perplexity_clean) + 1)\n",
    "# items_dirty = np.arange(1, len(perplexity_dirty) + 1)\n",
    "\n",
    "# # 定义柱子的宽度\n",
    "# width = 0.35\n",
    "\n",
    "# # 绘制柱状图\n",
    "# plt.bar(items_clean - width/2, perplexity_clean, width, label='clean')\n",
    "# plt.bar(items_dirty + width/2, perplexity_dirty, width, label='dirty')\n",
    "\n",
    "# plt.xlabel('Item数', fontproperties=font)\n",
    "# plt.ylabel('困惑度', fontproperties=font)\n",
    "# plt.title('Clean和Dirty的困惑度走势', fontproperties=font)\n",
    "# plt.legend(prop=font)\n",
    "\n",
    "# plt.show()\n",
    "# 创建横坐标值\n",
    "items_clean = np.arange(1, len(perplexity_clean) + 1)\n",
    "items_dirty = np.arange(1, len(perplexity_dirty) + 1)\n",
    "\n",
    "# 绘制散点图\n",
    "plt.scatter(items_clean, perplexity_clean, label='clean')\n",
    "plt.scatter(items_dirty, perplexity_dirty, label='dirty')\n",
    "\n",
    "plt.xlabel('Item数', fontproperties=font)\n",
    "plt.ylabel('困惑度', fontproperties=font)\n",
    "plt.title('Clean和Dirty的困惑度走势', fontproperties=font)\n",
    "plt.legend(prop=font)\n",
    "\n",
    "plt.show()\n",
    "# 创建数据列表\n",
    "data_list = [perplexity_clean, perplexity_dirty]\n",
    "\n",
    "# 创建标签列表\n",
    "labels = ['clean', 'dirty']\n",
    "\n",
    "# 绘制箱线图\n",
    "box = plt.boxplot(data_list, labels=labels, notch=True, patch_artist=True,\n",
    "                  boxprops=dict(facecolor='lightblue', color='black'),\n",
    "                  whiskerprops=dict(color='black'),\n",
    "                  capprops=dict(color='black'),\n",
    "                  medianprops=dict(color='red'),\n",
    "                  flierprops=dict(marker='o', markerfacecolor='red', markersize=5, linestyle='none'))\n",
    "\n",
    "plt.xlabel('类别', fontproperties=font)\n",
    "plt.ylabel('困惑度', fontproperties=font)\n",
    "plt.title('Clean和Dirty的困惑度分布', fontproperties=font)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copilot:\n",
    "如果你想比较两个变量（在这里是\"clean\"和\"dirty\"）对应的困惑度是否存在分布大小的差距，你可以使用统计检验。一个常用的方法是使用t检验，它可以检验两个独立样本的均值是否存在显著差异。\n",
    "\n",
    "以下是如何使用Python的scipy库进行t检验的示例：\n",
    "\n",
    "这段代码首先提取出\"clean\"和\"dirty\"的perplexity值，然后使用这些值进行t检验。最后，它打印出t统计量和p值。\n",
    "\n",
    "如果p值小于0.05（或你选择的其他显著性水平），那么你可以拒绝原假设（即两个样本的均值相等），并得出结论：两个样本的均值存在显著差异。否则，你不能拒绝原假设，即不能得出两个样本的均值存在显著差异的结论。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# 提取perplexity值\n",
    "perplexity_clean = [d['perplexity'] for d in data if d['label'] == 'clean']\n",
    "perplexity_dirty = [d['perplexity'] for d in data if d['label'] == 'dirty']\n",
    "\n",
    "# 进行t检验\n",
    "t_stat, p_val = stats.ttest_ind(perplexity_clean, perplexity_dirty)\n",
    "\n",
    "print(f\"t-statistic: {t_stat}\")\n",
    "print(f\"p-value: {p_val}\")\n",
    "# result:\n",
    "# t-statistic: 7.931112817260807\n",
    "# p-value: 4.021347489755902e-15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copilot:\n",
    "如果你想判断\"dirty\"的困惑度是否显著小于\"clean\"的困惑度，你可以使用单尾t检验。在scipy的ttest_ind函数中，这可以通过设置alternative参数为'less'来实现。\n",
    "\n",
    "以下是如何进行单尾t检验的示例：\n",
    "\n",
    "这段代码进行了一个单尾t检验，检验\"dirty\"的困惑度是否显著小于\"clean\"的困惑度。如果p值小于0.05（或你选择的其他显著性水平），那么你可以拒绝原假设（即\"dirty\"的困惑度大于或等于\"clean\"的困惑度），并得出结论：\"dirty\"的困惑度显著小于\"clean\"的困惑度。否则，你不能拒绝原假设，即不能得出\"dirty\"的困惑度显著小于\"clean\"的困惑度的结论。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行单尾t检验\n",
    "t_stat, p_val = stats.ttest_ind(perplexity_dirty, perplexity_clean, alternative='less')\n",
    "\n",
    "print(f\"t-statistic: {t_stat}\")\n",
    "print(f\"p-value: {p_val}\")\n",
    "# result:\n",
    "# t-statistic: -7.931112817260807\n",
    "# p-value: 2.010673744877951e-15"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
